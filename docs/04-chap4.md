\changechaptercolor{hokusai4}
# Eye movements through space interfere with visual processing of time-related words {#chap4}



<!-- NB: You can add comments using these tags -->

\initial{W}hen people make lexical decisions to words referring to the past or the future, they are faster when their manual responses are compatible with the mental timeline (MTL). That is, future words are responded to faster on the right than the left, while past words are responded to faster on the left than the right. This space-time congruency effect is interpreted to suggest that time words are represented along a spatial continuum that goes from left to right (past to future), at least in Western cultures that use reading-writing systems operating from left to right. All previous experiments used lateralized hand movements to register responses, which would evoke the directionality of writing. To evoke the directionality of reading, we investigated whether the space-time congruency effect would be replicated in a language task when responses were given using the eyes rather than the hand. Thus, participants were asked to make lateralized eye movements to indicate whether letter stimuli were real words or not (lexical decision). Eye movements were perturbed for responses incompatible with the direction of the MTL, both in terms of decision time and motor amplitude. These results confirm that time-related words are embodied through spatial movement in effector-independent motor networks and suggests that the spatial representation of time operates in a body-centered reference frame.^[Ce chapitre expérimental est une version adaptée du manuscrit au format de la thèse. Pour trouver le préprint de la version soumise au journal Acta Psychologica: Les stimuli, les scripts, les données et les figures sont disponibles en ligne: [https://osf.io/5ehnc/](https://osf.io/5ehnc/).]

## Introduction

One of the big challenges for theories of embodied language has been to show how they can handle the representation of abstracts words that do not directly refer to any physical object (e.g., *future*, *freedom*, *quantum physics*), and thus cannot be associated with direct sensorimotor information. Empirical evidence suggests that abstract words can indeed be associated with sensory interoceptive or emotional information [e.g., @connell_interoception_2018; @vigliocco_neural_2014; @villani_sensorimotor_2021]. The distinction between abstract and concrete words might not be as important as previously thought [e.g., @barsalou_moving_2018; @barsalou_challenges_2020; @kiefer_varieties_2020]. For example, recent meta-analyses of neuroimaging data have found strong overlapping activations for the processing of concrete and abstracts concepts [e.g., @desai_multifaceted_2018; @harpaintner_grounding_2020]. 

In the present article, we investigated the type of embodied information that contributes to the representation of words referring to the abstract concept of time. Time is not associated with any tangible temporal stimulus, there are no sensory receptors for time, and no "time area" in the brain. So, how do we represent and understand the abstract meaning of time? One of the major theoretical frameworks for the conceptualization of time is the mental timeline [MTL, for reviews, see @bender_mapping_2014; @bonato_when_2012; @cooperrider_across_2009]. This account claims that time is spatially organized along linear axes, particularly for concepts of temporal order (e.g., past, future). This spatialization of time is culturally dependent [e.g., @bonato_when_2012; @boroditsky_remembrances_2010; @nunez_contours_2012; @oliveri_representation_2009]. Converging cross-cultural data with distinct writing and reading systems have shown that Western cultures, with a left-to-right writing system, develop a left-past vs. right-future mental timeline. In cultures with a right-to-left writing system, the MTL is right-to-left [@ouellet_is_2010]. Therefore, it has been suggested that the left-to-right MTL results from extensive left-to-right reading and writing experience in orthographic systems that use that direction [e.g.,@fuhrman_mental_2007].

Several studies have shown that words related to the past or the future activate the MTL, which suggests that the semantic representation of time includes spatial information. A way to experimentally show this is to set up a laboratory task, in which participants respond leftwards or rightwards to words that refer to either the past or the future. If linguistic representations of time use space to convey the flow of time from the past to the future (i.e., activate a MTL), then asking participants to respond by moving their hand to the left for future words and to the right for past words creates interference, a space-time incongruency. Indeed, such a space-time congruency effect has been observed in various language tasks [e.g., @eikmeier_response_2015; @kong_space-time_2012; @maienborn_we_2015; @santiago_time_2007; @torralbo_flexible_2006; @ulrich_leftright_2010]. 

In these studies, the space-time congruency effect was strong when participants were asked to make explicit past/future judgments about words or sentences [e.g., @aguirre_potential_2017; @de_la_vega_mental_2016; @hutchison_can_2010; @kong_space-time_2012], but considerably reduced or absent when participants were instead asked to make judgments about a non-temporal dimension, such as word lexicality or semantic congruency [@maienborn_we_2015; @von_sobbe_space-time_2019, for a meta-analysis]. The reduction of the space-time congruency effect in tasks that do not involve direct and explicit processing of time was taken to suggest that the MTL is not activated automatically [@maienborn_we_2015; @von_sobbe_space-time_2019]. However, @grasso_as_2021 have recently demonstrated that one can find such space-time congruency effects in a language task that does not involve the explicit processing of time (i.e., lexical decision) as long as participants gave their response making hand movements (leftward or rightward) though not if they simply pressed a left or a right key [see also @sell_processing_2011; replicated by @scheifele_replication_2018]. This finding suggested that left- or rightward movement through space is a critical aspect for the representation of past or future words.

It is usually admitted that space-time congruency effects are due to the involvement of a single egocentric map where objects, actions and even notions are represented. The centre of this full-body egocentric spatial reference frame corresponds to the median axis of the body [e.g., @fuhrman_cross-cultural_2010; @miles_mapping_2010; for a discussion see for example @nunez_contours_2012]. As an alternative to that unitary framework, space-time congruency effects might be built on multiple reference frames, each being dedicated to a given spatial location and/or a given class of action and/or motor effector [for more information about these different spatial frames, see @ghafouri_contribution_2006]. In all previous experiments on space-time congruency effects, interference was generated using the hand as the response effector [e.g., @eikmeier_how_2015; @kong_space-time_2012; @maienborn_we_2015; @santiago_time_2007; @torralbo_flexible_2006; @ulrich_leftright_2010]. Therefore, it might be that the observed space-time congruency effect for words relies on a spatial reference frame specific to the hand and hand-movements. If words referring to time are represented in a full-body-centered reference frame, space-time congruency effects with words should not rely on a particular effector (the hand) but should generalize to different effectors.

In the present study, we investigate the space-time congruency effect in a language task using the eyes as response effectors. Thus, the present study has two goals. First, if the spatial representation of the temporal content of words derives from repeated directional movements produced during writing and reading, then the space-time congruency effect should not be limited to hand movements (used during writing) but should be observed for eye movements (used during reading) as well. Second, given that goal-directed movements require translation of spatial information into motor commands, a replication of the congruency effect with eye movements would mean that the representations of words referring to time are bound to general motor planning circuits that operate in a full-body-centered spatial frame [@rosenbaum_human_1991; @schmidt_motor_2019].

To this end, we performed a lexical decision experiment where participants responded using eye movements. French verbs and pseudo verbs were presented in conjugated form (i.e., past or future) on a screen, and participants had to decide as quickly as possible whether the stimulus was a word or a pseudoword by producing a saccade towards the left or the right side of the screen. Experimental design and stimuli were taken from @grasso_as_2021. The grammatical verbal system in French makes it possible to use the same word stem combined with a suffix that indicates either past tense (je marchais [I walked]; je rêvais [I dreamt]) or future tense (je marcherai [I will walk]; je rêverai; [I will dream]). Having the same word stem for different temporal conditions nicely controls for possible orthographic, lexical, and semantic confounds. Participants performed both congruent and incongruent conditions. In the congruent condition, eye movements were congruent with the MTL (i.e., past tense verbs required a leftward eye movement; future tense verbs a rightward eye movement). In the incongruent condition, eye movements were incongruent with the MTL.

## Materials and Methods 

### Participants 

The study involved 64 participants from Aix-Marseille University (Marseille, France). Nine participants were excluded from the analyses due to high errors rates or technical data acquisition issues. The remaining 58 participants (48 women, 54 right-handed) were all French native speakers, reported normal or corrected-to-normal vision and no neurological or psychiatric disorder. They ranged in age from 18 to 42 years old (*M* = 22.2; *SD* = 4.6) and signed informed-consent forms prior to participation. The study was conducted in accordance with the recommendations of the World Medical Association Declaration of Helsinki and it was approved by the Institutional Review Board of Aix-Marseille University.

### Design and Stimuli 

Because the main objective of this study was to determine whether we could replicate the space-time congruency effect observed when participants performed directed movement using the eyes as response effector, we used the design of the experiment 1 of @grasso_as_2021. We voluntarily chose the first experiment because it was the one with the strongest effect size (Cohen’s *d* = .74). In experiments 2 and 3 of their study, @grasso_as_2021 directly tested the role of temporal priming (i.e., whether “yesterday/tomorrow” preceded the conjugated verb) and found no influence of the prime on the space-time congruency effect. Stimuli were also taken from @grasso_as_2021 and consisted of 80 word stimuli (verbs) and 80 pseudoword stimuli (*pseudoverbs*, see Appendix in @grasso_as_2021. Each word or pseudoword was presented in past- or future-tense (e.g., je laissais/je laisserai and je gontrais/je gontrerai for words and pseudowords respectively), at the centre of the screen (see Figure \@ref(fig:chap-4-fig1)). To ensure that participants saw each word and each pseudoword only once, we created four counterbalanced lists of 160 stimuli each (80 words, 80 pseudowords) using a Latin-Square design. Half of the stimuli in each list were in the past tense, half were in the future tense. All stimuli were preceded by the pronoun “I” (je).

### Apparatus

Eye movements were recorded with an EyeLink 1000 system (SR Research, Mississauga, ON, Canada) with a high spatial resolution (0.01°) and a sampling rate of 1000 Hz. Viewing was binocular, but only the right eye was monitored. Stimuli were displayed on a 20-inch ViewSonic CRT monitor with a refresh rate of 85Hz and a screen resolution of 1024 x 768 pixels (30 x 40 cm). Stimuli were presented in black 37-point monospaced fonts (droid sans mono) on a grey background. The experiment was created using OpenSesame (Version 3.2.6; Mathôt et al., 2012). Participants were instructed to give a Yes (“it’s a word”) or No (“it’s not a word”) response in a lexical decision task by moving their eyes towards the right or left of the screen. The left and right correct response areas of the screen were spatially delimited by two virtual boundaries at +/-600 pixels from the centre of the screen. Participants were seated 86 cm from the monitor, such that every 3 characters equalled approximately 1° of visual angle. We used a chin-rest to minimize head movements. 

### Procedure 

The experiment was run in a quiet testing room. Participants received instructions both from the experimenter and from short sentences displayed on the screen. They were instructed to decide as rapidly and as accurately as possible whether the stimulus was a real French word or not (i.e., a lexical decision) by moving their eyes towards the left / right side of the screen. Half of the participants started with “yes” responses towards the left, half of the participants started with “yes” responses towards the right, and all participants switched response sides halfway through the experiment. Participants completed a short training session of 20 trials before the experimental trials began, and another short training session before switching response side. Each participant saw a total of 80 words and 80 pseudowords randomized across two counterbalanced blocks (“yes” to the right or “yes” to the left). When the “yes” response was to the right, future-tense words (20 stimuli) were congruent and past-tense words (20 stimuli) were incongruent (see Figure \@ref(fig:chap-4-fig1)). When the “yes” response was to the left, past-tense words were congruent (20 stimuli) and future-tense words were incongruent (20 stimuli). In each block, we therefore had 20 words per condition giving a total of 40 words, in addition to 40 future-tense and past-tense pseudowords. This design allowed us to present each stimulus in the past or future tense, during the first or the second part of the experiment, and in the congruent or incongruent condition. At the beginning of the experiment, the position of the eyes was calibrated using a 9-point calibration grid. The experiment started once the training session was completed. Each trial started with a drift correction dot presented at the centre of the screen. Participants were instructed to fixate this dot. Their fixation triggered the onset of a prime stimulus: (“hier” or “demain”; “yesterday” or “tomorrow” in English) that was displayed for 500ms, followed by a 400ms blank screen and then finally by the stimulus (i.e., a word or pseudoword). The stimulus remained on the screen until the participants responded by making a saccade. Saccades that crossed the virtual left or right boundaries were considered as responses, whereas saccades that did not cross the boundaries were considered as refixations or microsaccades (depending on their amplitude). Saccade response side was automatically registered when the eyes crossed the left or right boundary. Responses times corresponded to saccade latency, that is the time between the onset of the stimulus and the onset of the saccade. To assess the kinematic features of the saccade, we measured saccade amplitude expressed in degrees of visual angle (DVA). After each response, participants were instructed to fixate the central black dot to start the next trial. Therefore, a new trial did not start unless the gaze was at the centre of the screen. In each trial, the time interval between the onset of the stimulus and the new fixation dot was set to 2500ms. A break was offered to the participants every 20 trials. Half-way through the experiment (80 trials) participants were instructed to switch sides for yes/no responses. They were trained with the new response sides for 20 trials before completing the second half of the experiment. In all, each session with one participant lasted approximately 1 hour. 

\begin{figure}[htbp!]

{\centering \includegraphics[width=1\linewidth]{figures/chap-4-fig1} 

}

\caption{Task design. After the fixation dot, a prime (“yesterday” or “tomorrow”) was displayed, followed by the word or pseudoword. Participants made their lexical decision by moving their eyes towards the left or right side of the screen. The stimulus disappeared as soon as the eyes moved away from the stimulus. To start a new trial, participants had to fixate the central dot. In this example, the yes-response for the word conjugated in the future tense is congruent in Block 1 (rightward eye movement) but incongruent in Block 2 (leftward eye movement). A saccade was considered to be correct when it reached the left or right virtual boundaries. T1 corresponds to the onset-time of the saccade, T2 corresponds to the boundary-crossing time, and T3 corresponds to the landing time. Therefore, response latencies correspond to the response initiation time, which is the delay between the onset of the stimulus and onset of the saccade.}(\#fig:chap-4-fig1)
\end{figure}

### Data analyses

We recorded and analyzed response latency (in milliseconds), and saccade amplitude (in degrees of visual angle). Saccadic eye movements are stereotyped ballistic movements, that is, they cannot be modified once initiated [@gilchrist_saccades_2011], and they can be described by their latency and their angular rotation [i.e., spatial amplitude of the saccade, @findlay_active_2003; @findlay_visual_2001]. Saccade latency corresponds to the time needed to process the visual stimulus, to make a decision, and to program the motor response [@gilchrist_saccades_2011]. Saccade amplitude corresponds to the spatial distance between starting and landing positions of the eyes. Although this feature of the saccade may appear to be stereotyped [@edelman_influence_2007; @findlay_model_1999], it has been shown that linguistic factors (e.g., unusual orthographic patterns) influence saccade amplitude [@beauvillain_center_1996]. Given that the accuracy of goal-directed movements, including saccades, “depends on the quality of the encoding of spatial information by the central nervous system and the frame of reference” [@ghafouri_contribution_2006], we predicted that saccade programming as measured by saccade amplitude should be sensitive to the space-time frequency effect. Obtaining such an effect would imply that motor planning networks are involved in the spatial representation of words referring to time.

Both saccade latency and amplitude were analyzed using linear Mixed Effect Models (LMEs) with participants and items as crossed random effects [@baayen_analyzing_2008; @barr_random_2013]. Note that the space-time congruency effect is indexed by the interaction between the interaction between response side and verb tense. That is, when the side of response for a past-tense word (e.g., I walked) switches from left to right from one block to the other, the word stops being congruent and, instead, becomes incongruent. Similarly, when the side of the response for a future-tense word (e.g., I will walk) switches from left to right, the word stops being incongruent and becomes congruent (see Figure \@ref(fig:chap-4-fig1)). Data were fitted with lmer functions from the `lme4` package [@R-lme4] in the `R` statistical computing environment [Version 3.5.2, @r_core_team_r_2020]. We report unstandardized regression coefficients, standard errors (SEs), and t values. Fixed effects were deemed reliable if |t| was greater than 1.96 [@baayen_mixed-effects_2008]. As concerns model building, we used the maximal random structure model that reached convergence [@barr_random_2013], and this included by-participant and by-item random intercepts in all analyses that we report. In a forward stepwise model selection procedure, fixed and random effects of the models were selected according to the Akaike Information Criterion [AIC, @akaike_maximum_1973], the Bayesian Information Criterion [BIC, @schwarz_estimating_1978] using the `anova()` function of the package `lmerTest` package [@R-lmerTest] for model comparison. Therefore, fixed effects, random effects, and random slopes were only included if they significantly improved the model’s fit. Assumptions application were checked for each model: residual distribution were checked visually by plotting the residuals’ `Quantile-Quantile` (QQ) and the normality of the distribution of the random effects by plotting the QQ-plots with the `qqmath()` function [@sarkar_lattice_2008] and the `ranef()` function. Following the procedure described by @brysbaert_power_2018, we conducted power analysis based on 200 simulations with `powerSim` functions from the `simR` package [@green_simr_2016]. To create the figures, we used the `emmeans` package [@lenth_emmeans_2021] that allows us to compute the estimated marginals means (EMMs) for the interaction between response side and verb tense for each model (see Figure \@ref(fig:chap-4-fig2) and Figure \@ref(fig:chap-4-fig3)).

## Results

Saccade latency and saccade amplitude were analysed for the 58 participants. First, we removed trials containing blinks (2.91%), no-response trials (2.21%), trials with negative fixation duration (i.e., below 0ms, 2.41%), trials in which the initial position of the response saccade on the x-axis was outside the left or right boundaries (0.72%)  and trials with a total fixation duration below 100ms (anticipatory responses, 1.63%). We further discarded aberrant values corresponding to trials with latencies greater than the possible trial duration (i.e., above 2500ms) or less than 300ms (0.06% of trials in total), and trials with saccade amplitude greater than 30 degrees and less than 2 degrees (0.20%). Finally, after removing trials in which the participant gave an incorrect response (3.91%) latency outliers were removed following the classic ± 2.5 standard deviations from the participants’ mean response time (2.66% of the trials). Statistical analyses were conducted separately for words and pseudowords. 

### Words

For the analysis of saccade latencies, the final model included the following fixed effects: Time (past vs future), Side (left vs right) and their interaction, as well as word length (in pixels) and the number of word refixations (i.e., the number of fixations that were made on the word before answering) as covariates. The model also included by-participant and by-item random intercepts, and a random slope for Time, Side and number of refixations by-participants and a random slope for time by-items. 

Overall, participants were significantly faster to initiate a response saccade to the right side of the screen than to the left side (*b* = 20.63, *SE* = 10.14, *t* = 2.03, *p*< .05) but there was no significant difference for past versus future tense words (*b* = 11.86, *SE* = 8.62, *t* = 1.37, *p*= .17). Unsurprisingly, saccade latencies increased significantly with word length (*b* = 1.10, *SE* = 0.27, *t* = 4.30, *p*< .0001) and number of refixations (*b* = 84.97, *SE* = 5.83, *t* = 14.57, *p*< .0001). Importantly, the congruency effect, which is the interaction between Time and Side, was highly significant (*b* = -26.49, *SE* = 9.90, *t* = 2.68, *p*=.007). That is, saccade latencies to past-tense stimuli were slower when the correct (“yes”) response was on the right rather than the left. And saccade latencies for future-tense verbs were slower when the correct response was on the left versus the right (see Figure \@ref(fig:chap-4-fig2)). The power of this model (i.e., congruency and time) in 200 simulated studies was .81, 95%CI = [74, 86]. No other effect or interaction was significant.
	
The final model for the analysis of saccade amplitude included Time (past vs future), Side (left vs right) and their interaction as fixed effects, as well as number of refixations as a covariate. The model also included by-participant and by-item random intercepts, and a random slope for Side by-participant. Results showed a marginal effect of the number of word refixations (*b* = -0.05, *SE* = 0.02, *t* = 1.89, *p*=.06). More importantly, the interaction between Time and Side was significant (*b* = -0.20, *SE* = 0.08, *t* = 2.28, *p* =.02) reflecting the space-time congruency effect (see Figure \@ref(fig:chap-4-fig3)). The power of this model (i.e., congruency and time) in 1000 simulated studies was .66, 95% CI = [59, 73].  No other effect or interaction was significant.

### Pseudowords 

For the analysis of saccade latencies, the final model included Time (past vs future), Side (left vs right) and their interaction as fixed effects, as well as word length (in pixels) and number of refixations as covariates. The model also included by-participant and by-item random intercepts, and a random slope for Time, Side, and number of refixations by-participants and a random slope for Time by-items. Saccade latencies increased significantly as a function of pseudoword length (*b* = 0.81, *SE* = 0.26, *t* = 3.19, *p* < .001) and the number of refixations (*b* = 83.60, *SE* = 5.41, *t* = 15.45, *p* < .0001). The interaction between Time and Side was not significant (*b* = 3.17, *SE* = 9.74, *t* = 0.33, *p* = .74). No other effect or interaction was significant.

The final model for the analysis of saccade amplitude included Time (past vs future), Side (left vs right), number of pseudoword refixations and their interaction as fixed effects, and by-participant and by-item random intercepts. Results showed a significant effect of Side (*b* = 0.00, *SE* = 0.00, *t* = 3.05, *p* < .01), number of pseudoword refixations (*b* = 0.00, *SE* = 0.00, *t* = 4.35, *p* < .001) and a signification interaction between them (*b* = 0.00, *SE* = 0.00, *t* = 5.92, *p* <.001), that is, participants made more refixations before responding to the left than to the right. No other effect or interaction was significant. 

\begin{figure}[htbp!]

{\centering \includegraphics[width=1\linewidth]{figures/chap-4-fig2} 

}

\caption{Estimated marginal means from the mixed models (EMMs) for saccade latencies showing the interaction between Time (past vs future) and Side (left vs right) for words but not pseudowords. Error bars represent within subjects’ standard errors.}(\#fig:chap-4-fig2)
\end{figure}

\begin{figure}[htbp!]

{\centering \includegraphics[width=1\linewidth]{figures/chap-4-fig3} 

}

\caption{Estimated marginal means from the mixed models (EMMs) for saccade amplitude showing the interaction between Time (past vs future) and Side (left vs right) for words but not pseudowords. Error bars represent within subjects’ standard errors. .}(\#fig:chap-4-fig3)
\end{figure}

## Discussion 

The primary purpose of the present study was to investigate whether the space-time congruency effect was effector-dependent (bound to the arm/hand) or would generalize to another effector. To this end, we used the same lexical decision task design as @grasso_as_2021 but instead of using hand movements to register whether a stimulus was a real word or a pseudoword, participants made a saccade towards the left or right side of the screen. Congruent trials corresponded to leftwards eye-movements for past-tense words (or rightward for future-tense verbs) and incongruent trials to leftwards eye-movements for future-tense words (or rightward for past-tense verbs). 
	
Our results replicate the space-time congruency effect for words in the lexical decision task when the eyes are used as response effectors. As in a previous study [@grasso_as_2021], no such effect was found for pseudowords, which suggests that it taps into the nature of lexical word representations. The space-time congruency effect was observed for saccade latencies: leftward saccades were initiated more quickly for past-tense words, and the reverse pattern was found for future-tense words. In addition, a smaller but statistically significant space-time congruency effect was also found for saccade amplitude: participants made larger saccades on trials incongruent with the MTL. Saccade latency corresponds to the time needed to visually process the stimulus, to make the lexical decision, plus the time needed to program and launch the motor response [@gilchrist_saccades_2011]. Saccade amplitude is driven by the metrics and spatial parameters of the motor response. Therefore, the space-time congruency effect observed for saccade latencies can be considered an analog to the space-time congruency effect on lexical decision times previously obtained with hand responses. However, the space-time congruency effect for saccade amplitude is more likely driven by lexical interferences operating on the metrical adjustment and motor programming of the saccadic response. The parameters of the saccade cannot be modified once it is initiated [e.g., @edelman_influence_2007; @gilchrist_saccades_2011], which suggests that the calculation of the ballistic movement itself is affected by space-time incongruency. Note here that we did not make any prediction regarding the direction of the congruency effect on the amplitude of the saccade (i.e., shorter or longer saccade). The difference in amplitude between congruent and incongruent trials in itself shows that the processing of the temporal content of words interferes with saccade programming.	
	
These results have three main theorical implications. First, they replicate our previous finding [@grasso_as_2021] that a space-time congruency effect can be obtained when the processing of temporal information is not required to perform the task, which suggests that this effect taps into the lexical representations of words referring to time. As argued previously in the introduction, the key factor for obtaining this effect might be the involvement of spatially directed movement, and more precisely motor planning. 
	
Second, whereas most studies observed space-time congruency effects when participants respond with their hands, here we obtain the same effect with the eyes, which strongly suggests that the spatial reference frame underlying the effect is centered on the body and refers to extra-personal space. Put another way, the generalization of the space-time congruency effect to eye movements suggests that the processing of words referring to time relies on extra-personal and egocentric spatial coordinates. This spatial reference frame, in which left-to-right movement through space is coded independently from the effector, might therefore be re-used for the purpose of representing words that convey temporal information. This spatial reference frame, probably underpinned by parietal cortex, is known as “action-dependant” and “effector-independent” [see for example, @heed_functional_2011].
	
Third and most important, the significant interaction between the temporal content of words and the direction of eye movements suggests that the very lexical representation of words that refer to time contains spatially oriented information [see also @hartmann_pupillometry_2014; @stocker_eye_2016]. Interference arises because, in the incongruent conditions, left or right response-movements activate spatially oriented motor networks that are incompatible with the oriented spatial-temporal information belonging to the lexical representation of the word. These results are congruent with the idea that the spatial representation of the temporal content of words derives from culture-dependent directional movements that are habitually produced during writing and reading [e.g., @bonato_when_2012; @boroditsky_remembrances_2010; @fuhrman_mental_2007; @oliveri_representation_2009]. More generally, our results suggest that words conveying temporal information are not abstract since they are grounded in spatially oriented movements of the motor effectors that are used to write or read. The spatial-temporal information that contributes to the representation of these words therefore appears to be action-driven, centered on the body (midline) and related to basic motor programs engaged during writing and reading. 
	
## Supplementary materials {#suppCh4}

Open data, supplementary materials, as well as reproducible code are available at [https://osf.io/5ehnc](https://osf.io/5ehnc).

Aside from previously cited packages, several other packages have been used for the writing of this paper, among which the `ggrepel` and `ggplot2` packages for plotting [@R-ggrepel;@R-ggplot2] as well as the `tidyverse`, `sjstats`, `here`, `skimr`, and `glue` packages for code writing and formatting [@R-tidyverse;@R-sjstats;@R-glue;@R-here;@R-skimr].

## Acknowledgements

We would like to thank Jonathan Mirault, Françoise Vitu and Boris Quetard for tremendously helpful comments and suggestions.

Camille Grasso was supported by a doctoral fellowship of the French Ministry of Higher Education, Research, and Innovation. This study benefited from support of the Institute of Convergence ILCB (ANR-16-CONV-0002) and the Excellence Initiative of Aix-Marseille University A*MIDEX (ANR-11-IDEX-0001-02). 

<!-- create a new page for the summary -->
\newpage

<!-- center the box vertically, with a parameter to specify the ratio of space above to space below -->
\begin{vplace}[1]

\begin{summary}{Résumé du Chapitre\getcurrentref{chapter}}{\chaptercolor}

Lorsque les individus prennent des décisions lexicales concernant des mots se référant au passé ou au futur, ils sont plus rapides lorsque leurs réponses manuelles sont compatibles avec la ligne mentale temporelle (effets de congruence spatio-temporelle). Les multiples observations de ces effets de congruence spatio-temporelle se sont traduites dans l’hypothèse selon laquelle les concepts abstraits temporels seraient conceptualisés spatialement le long d’un continuum allant de la gauche vers la droite (du passé vers le futur), du moins dans les cultures occidentales qui utilisent des systèmes de lecture-écriture organisés de gauche à droite. Les expériences précédentes utilisaient des réponses manuelles pour enregistrer les réponses, ce qui évoquait l’orientation spatiale de l'écriture. Pour évoquer celle de la lecture, nous avons étudié si l'effet de congruence spatio-temporelle serait reproduit dans une tâche de décision lexicale lorsque les réponses étaient données avec des mouvements oculaires dirigés vers la gauche ou vers la droite, plutôt qu’avec la main. Nous avons donc adapté les tâches de décision lexicales présentées dans le chapitre 3 à une tâche d’analyse de mouvements oculaires. Ces analyses ont montré une perturbation du temps d’initiation de la saccade et de son amplitude dans les conditions d’incongruence spatio-temporelle (e.g., mouvement gauche pour mot au futur). Nous avons interprété ces résultats en faveur de processus incarnés pour la représentation des concepts abstraits temporels. Précisément, nos résultats suggèrent que les mots désignant des concepts abstraits temporels pourraient prendre racine lors de mouvements spatialement dirigés d’une part, et que le cadre de référence spatial utilisé pour représenter ces derniers serait relatif au corps entier, plutôt que centré sur les effecteurs de la main. Enfin, ces résultats sont cohérents avec l'hypothèse d'un rôle du mouvement dynamique pour l'émergence d'effets de congruence spatio-temporelle lors d'une tâche temporelle implicite, ainsi qu'avec la proposition d’un rôle déterminant des expériences d’écriture et de lecture qui lieraient ensemble coordonnées spatiales et temporelles. La prochaine étude examinera deux questions. La première interroge le rôle des processus moteurs lors de tâches temporelles explicites (où les effets de congruence spatio-temporelle émergent même dans des conditions de réponses statiques). En effet, si le mouvement dynamique (i.e., spatialement dirigé) est déterminant pour émergence d’effets de congruence spatio-temporelle mesurables, pourquoi des conditions avec réponses statiques (i.e., pression de touches au clavier) lors de tâches temporelles explicites semblent suffisantes pour l’émergence d’effets mesurables ? La seconde interroge plus directement la relation entre organisation spatiale du temps - la ligne mentale temporelle - et expérience de lecture.  

\end{summary}

\end{vplace}
